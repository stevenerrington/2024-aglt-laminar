function [out,hos,znrm] = HOSD_spike_detection(dat,params,varargin)


%[out,hos,pp_dat] = HOSD_spike_detection(data,[params])
%
% Univariate and multivariate pike detection with HOSD.
% 
% Input:
%
%   data - A struct variable with the following fields:
%       .dat - Samples x Channels array of continuous data. 
%       .fs  - Sampling rate 
%  params - Parameter structure as generated by HOS_default_params
%
% Output:
%
%   out - A struct variable with the following fields:
%      .spike_indices :  1 x Nspikes array of spike times in sampling units.
%      .spike_waves :  time x spike x channel array of spike waveforms in a
%                      window of duration params.windur. 
%      . tt   :  spike waveform window time
%      .hosd_filt_segments : (time * HOSD component * channel) x spike array of spike 
%                            detection filter output, windowed with a duration of 
%                            params.filt_segment.
%      .active_feature  :  component x spike array of component activation,
%                          computed by integrating the thresholded filter output 
%                          for each HOSD component within a window of params.filt_segment. 
%      .hos  :   hosminimal object containing the filter waveforms but not HOS themselves (to save space)
%      .srate : Data sampling rate
%      .params : parmeter vector.
%
%   hos - The full hosobject or mvhosd object used for the decomposition.
%   pp_dat - The preprocessed data array on which HOSD was run. 
%
% See also HOS_DEFAULT_PARAMS, HOSOBJECT, SORT_SPIKES

% C. Kovach 2021



debug = true;

if nargin > 1 && isfield(params,'dat') && ~isfield(dat,'dat')
    out = dat;
    dat = params;
    params = out.params;
end

if size(dat.dat,1)< size(dat.dat,2)
    warning(sprintf('Expecting a column vector but the 2nd dimension is bigger thatn the first.\nGoing to assume it just needs to be transposed.'))
    dat.dat = dat.dat';
end


nchan = size(dat.dat,2);


fprintf('\n%s: Detecting spikes...',mfilename)
if nargin<2 || isempty(params) 
    params = struct([]);
elseif ischar(params)
    params = struct([{params},varargin]);
end


i=1;
while i<length(varargin)
    params.(varargin{i}) = varargin{i+1};
    i=i+2;
end


params = HOSD_default_params(params);


if ~isempty(params.target_srate) && params.target_srate>0 && dat.fs > params.target_srate
   [a,b] = rat(params.target_srate/dat.fs);
   dat.orig_fs = dat.fs;
   fprintf('\nResampling from %0.1f to %0.1f Hz',dat.fs,dat.fs*a/b);
   dat.dat = resample(dat.dat,a,b);
   dat.fs = dat.fs*a/b;
end

multivariate = params.do_multivariate && nchan>1;

if ~multivariate && nchan > 1
    error('%s only handles 1 channel at a time if not doing mutlivariate HOSD.',mfilename)
end

if isempty(which('hosobject'))
    pth = fileparts(which(mfilename));
    addpath(genpath(fullfile(pth,'hosd_tools')))
end
    
if ischar(dat) 
    dat = load(dat);
end

params.randseed = reseed(params.randseed);
isn = any(isnan(dat.dat),2);
dat.dat(isn,:) = 0;

for k = 1:size(dat.dat,2)
     %%% DENOISING: LINE NOISE AND TRANSIENTS
    if params.dbt_denoising
    %     figure

    %     [xdn,~,~,spk] = dbtDenoise(double(dat.dat),dat.fs(1),.25,'make plot',true,'remove spikes',false);
        [xdn(:,k),~,~,spk] = dbtDenoise(double(dat.dat(:,k))-mean(double(dat.dat(:,k))),dat.fs(1),.25,'make plot',false,'remove spikes',false);
        if ~spk.remove_spikes
             spk.filter  =1;
        end
    else
        xdn(:,k)=double(dat.dat(:,k));
        spk.filter=1;
    end
end
spk.filter = spk.filter.*(~isn);

%%% Filter in MUA range
% mua = hpfilt(xdn-mean(xdn),[dat.fs(1) params.highpass ]);
[B,A] = butter(2,params(1).highpass/dat.fs*2,'high');
mua = filtfilt(B,A,xdn-mean(xdn));

out.normalization = nanstd(mua);
z = mua./out.normalization + 0./(spk.filter>.5);
if params.normalize_power
    powsmw=hann(.5*dat.fs);
    powsmw = powsmw./sum(powsmw);
%             pow = convn(xdn.^2,powsmw,'same');
    pow = convn(z.^2,powsmw,'same');
%             xdnrm = xdn./(sqrt((pow + mean(pow))/2));
    znrm = z./sqrt((pow + nanmean(pow))/2);
    out.normalization = out.normalization*(sqrt((pow + nanmean(pow))/2));
    
%             znrm = zscore(mua./pow)+ 0./(spk.filter>.5);
else
%             xdnrm = xdn;
    znrm = z;
end


if isa(params.outlier_rejection,'function_handle')
    znrm = params.outlier_rejection(znrm);    
elseif isscalar(params.outlier_rejection)
    znrm = iterz(znrm,params.outlier_rejection);
end

if multivariate && params.PCA>0
   C = cov(znrm);
   [u,l] = svd(C);
   u = u*diag(sign(sum(u)));
   if params.PCA > 1
      pckeep = params.PCA;
   else
       exvar = cumsum(diag(l))./sum(l(:));
       pckeep = find(exvar>params.PCA,1);
   end
%    W = u(:,1:pckeep)*u(:,1:pckeep)';
   params.pre_multiply = u(:,1:pckeep)*diag(sqrt(diag(l(1:pckeep,1:pckeep))).^-1);
   znrm = znrm*params.pre_multiply;
   nchan = pckeep;
end

if multivariate && params.ncomp_per_chan > 0
    params.ncomp = params.ncomp_per_chan*nchan;
end

if isfield(dat,'hos')
    params.ncomp = length(dat.hos);
end
%%% Create HOSD object
% hos(nchan,params.ncomp) = hosobject(3); 
% hos(:).initialize(round(params.windur*dat.fs(1)),dat.fs(1),params.lowpass,[],[],'window',params.window,'highpass',params.highpass,params.HOSD_opts{:});
hos0 = hosobject(3); 
hos0.initialize(round(params.windur*dat.fs(1)),dat.fs(1),params.lowpass,[],[],'window',params.window,'use_adaptive_threshold',false,'highpass',params.highpass,params.HOSD_opts{:});
% povlp =  max(params.poverlap,params.ncomp*(length(znrm)/hos(1).buffersize * (hos(1).buffersize + length(hos(1).B)))*16./params.limit_memory * nchan^params.do_multivariate);
povlp =  max(params.poverlap,(length(znrm)/hos0(1).buffersize * (hos0(1).buffersize + length(hos0(1).B)))*16./params.limit_memory * nchan^params.do_multivariate);
if povlp ~=params.poverlap
    fprintf('\nTo meet memory constraints, window separation is increased to: %0.2f',povlp)
end
% for k = 1:numel(hos)
%     hos(k).poverlap = povlp; %params.poverlap;
% end
hos0.poverlap = povlp;
%%% function with which to compute skewness
skewfun = @(x)nanmean(x.^3)./nanmean(x.^2).^(3/2);

zresid=znrm;
plh = params.online_plot;
if ~multivariate
%     %%% APPLY HOSD TO DATA
%     [A,B] = hos.get_block(znrm,params.hosd_maxiter,params.online_plot); % A and B are segmented data after and before alignment, respectively.
%     %%% Apply the feature identification filter
%     xfilt = hos.xfilt(znrm);

    for nk = 1:params.ncomp
        
        if ~isfield(dat,'hos') %Use existing hos object, if it is given as a field with dat.
            hos(nk) = hosobject(hos0);
            [~,~,~,~,~,plh] = hos(nk).get_block(zresid,25,plh,[],nk);
        else
            hos(nk) = dat.hos(nk);
        end
        xrec = hos(nk).xrec(zresid);
        xfilt(:,nk) = hos(nk).xfilt(zresid);
        zresid = zresid-xrec;
        skf(nk) = skewfun(xfilt(:,nk));
        if nk > 1 && skf(nk-1)< params.skewness_threshold && skf(nk)< params.skewness_threshold
            fprintf('Skewness was under %0.3f for 2 successive components... stopping at %i.',params.skewness_threshold,nk)
            break
        else
            fprintf('\nComponent %i final skewness: %0.2f',nk,skf(nk))
        end
    end
    skw = skewfun(xfilt); % Compute skewness on filtered data
    xfnrm = var(xfilt(:));
%     xfilt(isnan(xfilt))=0;
else

%     if params.ncomp_per_chan > 0
%         params.ncomp = params.ncomp_per_chan*nchan;
%     end
    xfnrm = 0;
    fprintf('\nDoing multivariate HOSD...')
    for nk = 1:params.ncomp

%         nfp = 0;
%         for k = 1:nchan
%             nfp=fprintf([repmat('\b',1,nfp),'\nComp. %i,estimating HOS for chan. %i'],nk,k)-nfp;
%             X(:,:,k) = hos0.chop_input(zresid(:,k));
%             Gpart(:,:,k) = hos0.partial_delay_filt(X(:,:,k),true,true); 
%             if k==1
%                 X(:,:,nchan)=0;
%                 Gpart(:,:,nchan)=0;
%             end
%         end

        if ~isfield(dat,'hos')
            mvhos(nk) = mvhosd(hos0);
            mvhos(nk).subspace_dim = params.subspace_dim;
            mvhos(nk).use_adaptive_threshold=false;
    %         mvhos(nk).filterfft = nanmean(Gpart,2);
    %         mvhos(nk).feature = nanmean(X,2);
    %         [~,~,plh] = mvhos(nk).align(X,Gpart,25,plh,nk);
            [~,~,plh] = mvhos(nk).get_block(zresid,25,plh,[],nk);
        else
            mvhos(nk) = dat.hos(nk);
        end
        %[~,xfilt(:,nk,:)] = mvhos(nk).xfilt(permute(zresid,[1 3 2]));
        [~,xfilt] = mvhos(nk).xfilt(permute(zresid,[1 3 2]));

        skf(nk) = skewfun(sum(xfilt,3));
        if skf(nk)<0
            mvhos(nk).filterfun = -mvhos(nk).filterfun;
            [~,xfilt] = mvhos(nk).xfilt(permute(zresid,[1 3 2]));
        end
%        if any(skewfun(xfilt)> skf(nk))
%           keepf = skewfun(xfilt)>skf(nk);
%           mvhos(nk).feature(:,:,~keepf)=0;
%           mvhos(nk).filterfun(:,:,~keepf)=0;
%           [~,xfilt] = mvhos(nk).xfilt(permute(zresid,[1 3 2]));
%        end

        xrec = mvhos(nk).xrec(zresid);
        zresid = zresid-squeeze(xrec);

        if nk > 1 && skf(nk-1)< params.skewness_threshold && skf(nk)< params.skewness_threshold 
            fprintf('Skewness under %0.3f for the last 2 components... stopping at %i.',params.skewness_threshold,nk)
            break
        elseif isnan(skf(nk))
            break
        else
           fprintf('\nComponent %i final skewness: %0.2f',nk,skf(nk))
        end
        xfnrm = xfnrm+var(xfilt(:));
    end
    skw = skf;
%     xfilt = mvhos.xfilt(permute(znrm,[1 3 2]));
end

% skw = skewfun(sum(xfilt,3)); % Compute skewness on filtered data

params.keepc = min(find(skw>=params.skewness_threshold,1,'last'),params.ncomp);
if isempty(params.keepc)
    params.keepc = 1;
end


% xfilt = xfilt(:,1:params.keepc,:);
if isempty(params.keepc)
    params.keepc= 1;
end
fprintf('\nComponents retained: %i',params.keepc)
%%% Filtered and thresholded data
if ~multivariate
    xthr = hos(1:params.keepc).xthresh(znrm);
else
     xthr = 1;
%     zresid = permute(znrm,[1 3 2]);
%     for k = 1:params.keepc
%         xthr(:,k,:) = sparse(mvhos(k).xthresh(permute(zresid,[1 3 2])));
%         zresid = zresid-mvhos(k).xrec(zresid);
%     end
end
    
if ~any(xthr(:))
    %%% This is a hack to ensure filtering returns something even
    %%% when nothing is there. No spikes otherwise causes an error.  
   if ~multivariate
       hos(1).filterfun= -hos(1).filterfun ;
       hos(1).feature = -hos(1).feature;
       hos(1).use_adaptive_threshold = false;
    %    xthr = hos(1:params.keepc).xthresh(znrm);   
   
        xthr = hos(1:params.keepc).xthresh(z);
%    else
%        mvhos(1).filterfun= -hos(1).filterfun ;
%        mvhos(1).feature = -hos(1).feature;
%        mvhos(1).use_adaptive_threshold = false;
%        %xthr = mvhos(1:params.keepc).xthresh(permute(z,[1 3 2]));
%        zresid = permute(znrm,[1 3 2]);
%        for k = 1:params.keepc
%             xthr(:,k,:) = sparse(mvhos(k).xthresh(permute(zresid,[1 3 2])));
%             zresid = zresid-mvhos(k).xrec(zresid);
%        end
     end

end

if ~isfield(params,'use_components') || isempty(params.use_components)
    used_components = true(1,params.keepc);
else
    used_components = params.use_components;
end
if ~multivariate
    %%%%% Get the peaks in the thresholded data %%%%%
    %%% Apply tolerance smoothing
    smxthr = convn(squeeze(full(xthr)),hann(round(2*params.tolerance*dat(1).fs(1))),'same');
    %%% Here combining over components and smoothing
    if params.check_features %Test whether a feature likely represents an artifact based on frequency and periodicity
        for k = 1:params.keepc
          if used_components(k)
              sm = smxthr(:,k);
              %Ignore events in artifactual features
              [~,pks] = getpeak2(sm);
              kpfeat=max(zscore(abs(fft((pks==1)-mean(pks==1)))))<15; % This criterion rejects he feature if its spectrum contains any large peaks
              if ~kpfeat
                fprintf('\nSpectral lines detected in component %i; discarding it from spike detection.',k)
                smxthr(:,k) = 0;
              end
              used_components(k) = kpfeat;
          end
        end
    end
    [~,pks] = getpeak2(sum(smxthr,2));
      
else
    %%%%% Get the peaks in the thresholded data %%%%%
    %%% Apply tolerance smoothing
    zresid = permute(znrm,[1 3 2]);
    smxthr=0;
    for k = 1:params.keepc
        
        xthr = mvhos(k).xthresh(permute(zresid,[1 3 2]));
        xr = mvhos(k).xrec(zresid);
        
        if used_components(k)
            sm = convn(squeeze(full(xthr)),hann(round(2*params.tolerance*dat(1).fs(1))),'same');
            if params.check_features %Test whether a feature likely represents an artifact based on frequency and periodicity
                                     %Ignore events in artifactual features
                [~,pks] = getpeak2(sm);
                kpfeat=max(zscore(abs(fft((pks==1)-mean(pks==1)))))<15; % This criterion rejects he feature if its spectrum contains any large peaks
                if ~kpfeat
                    fprintf('\nSpectral lines detected in component %i; discarding it from spike detection.',k)
                end
            else
                kpfeat=true;
            end
            used_components(k) = kpfeat;
            smxthr = kpfeat*sm + smxthr;
        end
        zresid = zresid-xr;

    end
    %%% Here combining over components and smoothing
    [~,pks] = getpeak2(smxthr);
end

params.use_components = used_components;
%%% Here separately for each component
% [~,pksep] = getpeak2(smxthr);

pkts = [];
% compno = [];
for k = 1:size(pks,2)
    pkts = [pkts,find(pks(:,k)'==1)];
end

% pksm = convn(full(pksep==1),ones(round(tolerance*dat.fs(1)),1),'same')>0;

pkts = unique(pkts,'stable');
%     compno = pksm(pkts,:)==1;
[~,compno] = max(smxthr(pkts,:),[],2); 
compno = compno.*(sum(smxthr(pkts,:),2)~=0);
pkts = pkts(~all(compno==0,2));
%     compno = compno(~all(compno==0,2),:);

 %%% Create segmentation matrix around spike times
[T,tt] = chopper(params.windur*[-.5 .5]-[0 1/dat.fs(1)],pkts/dat.fs(1),dat.fs(1));
pkts = pkts(:,~any(T<1 | T>length(z)));
compno = compno(~any(T<1 | T>length(z)),:);
T = T(:,~any(T<1 | T>length(z)));

spike_indices = pkts;
% spike_waves = dat.dat(T);
if params.get_spike_waveforms
    spike_waves = single(mua(T + size(mua,1)*permute(0:size(mua,2)-1,[1 3 2])));
end
if isempty(pkts)
    fprintf('\nNo spikes were detected!')
    if multivariate
        hos = mvhos(1:params.keepc);
    end

    out = struct('params',params,'spike_indices',spike_indices,'spike_waves',spike_waves,'hosd_filt_segments',[],'tt',[],'hos',hosminimal(hos(1:params.keepc)),'srate',dat(1).fs(1),'active_feature',[],'used_components',used_components,'normalization',out.normalization);
    return
end

zresid = znrm;
for k = 1:params.keepc
    if multivariate
%         [~,xf] = mvhos(k).xfilt(zresid);

        [xf] = mvhos(k).xfilt(zresid);
        xthr = mvhos(k).xthresh(zresid);
        xthrnorm = xthr./nanstd(xf(:));
        
    else
        xf = xfilt(:,k,:);
        xthrnorm = xthr(:,k)./nanstd(xf(:));
    end
    xfilt_norm = xf./nanstd(xf);
    
%     xf = xfilt(:,k,:);
%     xfilt_norm(:,k,:) = xfilt(:,k,:)./nanstd(xf(:));
%     xthrnorm(:,k,:) = xfilt(:,k,:)./nanstd(xf(:));
% end
% % xfilt_norm = xfilt(:,1:params.keepc,:)./nanstd(xfilt(:,1:params.keepc,:));
% % xthrnorm = xthr./nanstd(xfilt(:,1:params.keepc,:));
% for k = 1:params.keepc
    for kk = 1:size(xfilt_norm,3)
%         hosd_filt_segment(:,k,:,kk) = xfilt_norm(T(abs(tt)<=params.filt_segment,:) + (k-1)*size(xfilt,1) +  (kk-1)*size(xfilt,1)*size(xfilt,2)); %#ok<*AGROW>
        hosd_filt_segment(:,k,:,kk) = xfilt_norm(T(abs(tt)<=params.filt_segment,:) +  (kk-1)*size(xfilt_norm,1)); %#ok<*AGROW>
        if k ==1 && kk==1
            hosd_filt_segment(:,params.keepc,size(xfilt,3),size(xfilt_norm,3)) =0;
        end
    end
    %     active_feature(:,k) =  any(xthr(T(abs(tt)<=params.filt_segment,:) + (k-1)*length(xfilt))>0,1);
%     active_feature(:,k) =  sum(xthrnorm(T(abs(tt)<=params.filt_segment,:) + (k-1)*length(xfilt)),1);
 %   active_feature(:,k) =  sum(xthrnorm(T(abs(tt)<=params.filt_segment,:) ),1);
    active_feature(:,k) =  max(xthrnorm(T(abs(tt)<=params.filt_segment,:) ),[],1);
    
    if multivariate
        zresid = zresid - squeeze(mvhos(k).xrec(zresid));
    end
    
end


hosd_filt_peak = squeeze(max(hosd_filt_segment));
hosd_filt_segment = reshape(hosd_filt_segment,size(hosd_filt_segment,1)*size(hosd_filt_segment,2),size(hosd_filt_segment,3),size(hosd_filt_segment,4));
hosd_filt_segment(isnan(hosd_filt_segment))=0;

fprintf('\n%i spikes detected',length(spike_indices))

if multivariate
    hos = mvhos(1:params.keepc);
%     out.hos = hosminimal(mvhos);
else
    hos = hos(1:params.keepc);
end

out = struct('params',params,'spike_indices',spike_indices,'spike_waves',spike_waves,'hosd_filt_segments',hosd_filt_segment,'tt',tt,'hos',hosminimal(hos),'srate',dat(1).fs(1),'active_feature',active_feature','used_components',used_components,'normalization',out.normalization,'hosd_filt_peak',hosd_filt_peak);

%%% Retain following fields from the input data structure, if they
%%% are present
checkfields = {'chan','block','study','date','time','subject','notes'};
fldn= fieldnames(dat);
getfields = fldn(ismember(lower(fldn),checkfields));
for k = 1:length(getfields)
    out.(getfields{k}) = dat.(getfields{k});
end
if ~isempty(params.output_file.basename) ||~isempty(params.output_file.spikes) 
    [pth,fn] = fileparts(params.output_file.spikes);
    if isempty(pth)
        pth = params.output_file.basepath;
    end
    if isempty(fn)
        fn = [params.output_file.basename,'_spikes.mat'];
    end
    out.params.output_file.spikes = fullfile(pth,fn);
    save(out.params.output_file.spikes,'-struct','out');
end
