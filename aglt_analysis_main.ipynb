{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward and feedback interactions for sequence learning in the macaque frontotemporal network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise and setup workspace\n",
    "In this section, we will set up the workspace required for data analysis and visualization. The code is organized into several key steps:\n",
    "\n",
    "### Importing Toolboxes and Dependencies\n",
    "We start by importing essential Python libraries such as pandas for data manipulation, numpy for numerical operations, and matplotlib for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import toolboxes and dependencies -----------------------------------------------------#\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Directories to the System Path\n",
    "To ensure that Python can locate all necessary modules, we add the root directory and its subdirectories to the system path. This allows us to seamlessly import custom functions and modules from different locations within the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add root & subdirectories to path -----------------------------------------------------#\n",
    "def init_path(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively add a directory and all its subdirectories to the system path.\n",
    "    \"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        if dirpath not in sys.path:\n",
    "            sys.path.append(dirpath)\n",
    "                  \n",
    "          \n",
    "if sys.platform == 'win32':  \n",
    "    init_path(r'C:\\KIKUCHI-LOCAL\\script\\2024-aglt-laminar')\n",
    "elif sys.platform == 'darwin':\n",
    "    init_path(r'/Users/stevenerrington/Desktop/Projects/2024-aglt-laminar')  \n",
    "#------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Custom Functions\n",
    "We import custom functions from various modules specific to our project. These functions include setup procedures, MATLAB-related functions, spike analysis tools, behavioral analysis utilities, and figure generation tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import custom functions ---------------------- ----------------------------------------#\n",
    "from setup_workspace import *\n",
    "from matlab_functions import *\n",
    "from nphys_functions import *\n",
    "from beh_functions import *\n",
    "from figure_functions import *\n",
    "#------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading Experiment Logs and Defining Data Directories\n",
    "Finally, we import and clean the experimental logs necessary for the analysis. This step includes setting up directories for data storage and retrieval, and ensuring that the logs are in a suitable format for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import experiment logs and define data directories ------------------------------------#\n",
    "dirs = set_directories()                                    # Get directories\n",
    "ephysLog, stimulusLog, spike_log = import_exp_map()         # Get experimental logs\n",
    "ephysLog = clean_exp_map(ephysLog)                          # Clean experiment log\n",
    "spike_log = clean_spike_map(spike_log)                      # Clean spike log\n",
    "#------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following these steps, we prepare the environment for subsequent data analysis tasks, ensuring that all dependencies and custom functions are correctly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional properties of auditory and frontal cortex neurons to auditory sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify modulatory activity of neurons across different epochs\n",
    "\n",
    "To identify the activity of neurons in response to different task-events, we will align the spiking activity of isolated neurons to the trial start cue, the sequence onset, and the reward modulation.\n",
    "\n",
    "Here we define parameters important for this analysis, and identify the area from which neurons are recorded based on their label in the recording log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set parameters\n",
    "ops = {\n",
    "    'timewin': np.arange(-1000, 5001, 1),  # -1000 to 5000 inclusive\n",
    "    'bl_win': np.arange(-150, -49, 1),     # -150 to -50 inclusive\n",
    "    'freq': [2, 60],                       # Frequencies range from 2 to 60\n",
    "    'sdf_filter': 'PSP',\n",
    "    'sig_threshold': 2,\n",
    "    'min_sig_time': 50\n",
    "}\n",
    "\n",
    "# Set parameters for sound specific stimuli\n",
    "ops['sound_sdf_window'] = np.arange(-200, 601, 1)  # -200 to 600 inclusive\n",
    "sound_onset_ms = [0, 563, 1126, 1689, 2252]\n",
    "zero_offset = abs(ops['timewin'][0])\n",
    "\n",
    "# Define neurons\n",
    "auditory_neuron_idx = np.where(np.isin(spike_log['area'], ['R', 'A1', 'RM', 'dSTS']))[0]\n",
    "frontal_neuron_idx = np.where(np.isin(spike_log['area'], ['44', '45', 'FOP']))[0]\n",
    "\n",
    "# Initialize loop variables\n",
    "neuron_count = 0\n",
    "neuron_sdftrialstart_out = []\n",
    "neuron_sdfviol_out = []\n",
    "neuron_sdfseq_out = []\n",
    "neuron_sdfreward_out = []\n",
    "neuron_sdfsound_out = []\n",
    "neuron_baseline_out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_i in range(ephysLog.shape[0]):\n",
    "    datafile = ephysLog.loc[session_i, 'session']\n",
    "    print(f'Session {session_i + 1} of {ephysLog.shape[0]} | {datafile}')\n",
    "    \n",
    "    # Load event table data\n",
    "    event_table = pd.read_csv(os.path.join(dirs[\"py_data\"], 'event_table', datafile + '-events.csv'))        \n",
    "\n",
    "    # Adjust onsets based on audio latency measures\n",
    "    session_audio_latency = scipy.io.loadmat(r'C:\\KIKUCHI-LOCAL\\script\\2024-aglt-laminar\\data-extraction\\doc\\session_audio_latency.mat')\n",
    "    session_audio_latency = session_audio_latency['session_audio_latency']\n",
    "    event_table['stimulusOnset_ms'] += session_audio_latency[session_i][0][:,0]\n",
    "\n",
    "    # Create a violation time event for alignment\n",
    "    create_violation_alignment_event(event_table)\n",
    "\n",
    "    # Find all neurons in the given session\n",
    "    neuron_list = spike_log['unitDSP'][spike_log['session'] == datafile]\n",
    "    \n",
    "    # For each neuron recorded in the session    \n",
    "    for neuron in neuron_list:\n",
    "        # Update the loop variables\n",
    "        neuron_count += 1\n",
    "        sound_sdf = []\n",
    "        count = 0    \n",
    "    \n",
    "        # Load the spike times from the datafile\n",
    "        spike_times = np.loadtxt(os.path.join(dirs[\"py_data\"], 'spike_times', datafile + '-' + neuron + '-spk.txt'), delimiter=',')\n",
    "        spike_times = spike_times.astype(int)\n",
    "        \n",
    "         # Generate a spike density function\n",
    "        sdf = spk_convolve(spike_times, np.max(spike_times)+10000, 'PSP')\n",
    "\n",
    "        # Aligned spike density functions and rasters    \n",
    "        align_event = 'trialStart_ms'\n",
    "        align_times = event_table[align_event].to_numpy(dtype=int)\n",
    "        sdf_aligned_trialStart, raster_aligned_trialStart = spk_align(sdf, spike_times, align_times, ops['timewin'])\n",
    "\n",
    "        align_event = 'stimulusOnset_ms'\n",
    "        align_times = event_table[align_event].to_numpy(dtype=int)\n",
    "        sdf_aligned_seq, raster_aligned_seq = spk_align(sdf, spike_times, align_times, ops['timewin'])\n",
    "\n",
    "        align_event = 'violation_ms'\n",
    "        align_times = event_table[align_event].to_numpy(dtype=int)\n",
    "        sdf_aligned_viol, raster_aligned_viol = spk_align(sdf, spike_times, align_times, ops['timewin'])\n",
    "\n",
    "        align_event = 'rewardOnset_ms'\n",
    "        align_times = event_table[align_event].to_numpy(dtype=int)\n",
    "        sdf_aligned_reward, raster_aligned_reward = spk_align(sdf, spike_times, align_times, ops['timewin'])\n",
    "        \n",
    "        # Store SDFs for different alignment events\n",
    "        neuron_sdftrialstart_out.append(sdf_aligned_trialStart);\n",
    "        neuron_sdfseq_out.append(sdf_aligned_seq);\n",
    "        neuron_sdfviol_out.append(sdf_aligned_viol);\n",
    "        neuron_sdfreward_out.append(sdf_aligned_reward);\n",
    "\n",
    "        # Select data for the baseline window\n",
    "        baseline_data = sdf_aligned_trialStart[:, zero_offset + ops['bl_win']]\n",
    "        neuron_baseline = np.nanmean(baseline_data, axis=1)\n",
    "        neuron_baseline_out.append(neuron_baseline)\n",
    "        \n",
    "        # Process each trial for the current neuron\n",
    "        for trial_i in range(len(event_table)):\n",
    "            if event_table.loc[trial_i, 'cond_label'] != 'error':  # Skip error trials\n",
    "                for sound_i in range(5):  # Loop through each sound in the trial\n",
    "                    count += 1\n",
    "                    \n",
    "                    # Extract and store relevant SDF information for each sound\n",
    "                    sdf_value = sdf_aligned_seq[trial_i, zero_offset + ops['sound_sdf_window'] + sound_onset_ms[sound_i]]\n",
    "                    raster_value = raster_aligned_seq[trial_i] - sound_onset_ms[sound_i]\n",
    "                    \n",
    "                    # Ensure `cond_value` is a valid key\n",
    "                    cond_value = event_table.loc[trial_i, 'cond_value']\n",
    "                    if cond_value in stimulusLog[f'sound_{sound_i + 1}_code'].index:\n",
    "                        sound_code = stimulusLog[f'sound_{sound_i + 1}_code'][cond_value]\n",
    "                    else:\n",
    "                        sound_code = 'Unknown'  # Handle missing keys\n",
    "\n",
    "                    sound_sdf.append([\n",
    "                        sdf_value,\n",
    "                        raster_value,\n",
    "                        sound_code,\n",
    "                        f'position_{sound_i + 1}',\n",
    "                        event_table.loc[trial_i, 'cond_label']\n",
    "                    ])\n",
    "                    \n",
    "        neuron_sdfsound_out.append(sound_sdf)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing activity for neuron 1 of 2298...\n",
      "Normalizing activity for neuron 2 of 2298...\n",
      "Normalizing activity for neuron 3 of 2298...\n",
      "Normalizing activity for neuron 4 of 2298...\n",
      "Normalizing activity for neuron 5 of 2298...\n",
      "Normalizing activity for neuron 6 of 2298...\n",
      "Normalizing activity for neuron 7 of 2298...\n",
      "Normalizing activity for neuron 8 of 2298...\n",
      "Normalizing activity for neuron 9 of 2298...\n",
      "Normalizing activity for neuron 10 of 2298...\n",
      "Normalizing activity for neuron 11 of 2298...\n",
      "Normalizing activity for neuron 12 of 2298...\n",
      "Normalizing activity for neuron 13 of 2298...\n",
      "Normalizing activity for neuron 14 of 2298...\n",
      "Normalizing activity for neuron 15 of 2298...\n",
      "Normalizing activity for neuron 16 of 2298...\n",
      "Normalizing activity for neuron 17 of 2298...\n",
      "Normalizing activity for neuron 18 of 2298...\n",
      "Normalizing activity for neuron 19 of 2298...\n",
      "Normalizing activity for neuron 20 of 2298...\n",
      "Normalizing activity for neuron 21 of 2298...\n",
      "Normalizing activity for neuron 22 of 2298...\n",
      "Normalizing activity for neuron 23 of 2298...\n",
      "Normalizing activity for neuron 24 of 2298...\n",
      "Normalizing activity for neuron 25 of 2298...\n",
      "Normalizing activity for neuron 26 of 2298...\n",
      "Normalizing activity for neuron 27 of 2298...\n",
      "Normalizing activity for neuron 28 of 2298...\n",
      "Normalizing activity for neuron 29 of 2298...\n",
      "Normalizing activity for neuron 30 of 2298...\n",
      "Normalizing activity for neuron 31 of 2298...\n",
      "Normalizing activity for neuron 32 of 2298...\n",
      "Normalizing activity for neuron 33 of 2298...\n",
      "Normalizing activity for neuron 34 of 2298...\n",
      "Normalizing activity for neuron 35 of 2298...\n",
      "Normalizing activity for neuron 36 of 2298...\n",
      "Normalizing activity for neuron 37 of 2298...\n",
      "Normalizing activity for neuron 38 of 2298...\n",
      "Normalizing activity for neuron 39 of 2298...\n",
      "Normalizing activity for neuron 40 of 2298...\n",
      "Normalizing activity for neuron 41 of 2298...\n",
      "Normalizing activity for neuron 42 of 2298...\n",
      "Normalizing activity for neuron 43 of 2298...\n",
      "Normalizing activity for neuron 44 of 2298...\n",
      "Normalizing activity for neuron 45 of 2298...\n",
      "Normalizing activity for neuron 46 of 2298...\n",
      "Normalizing activity for neuron 47 of 2298...\n",
      "Normalizing activity for neuron 48 of 2298...\n",
      "Normalizing activity for neuron 49 of 2298...\n",
      "Normalizing activity for neuron 50 of 2298...\n",
      "Normalizing activity for neuron 51 of 2298...\n",
      "Normalizing activity for neuron 52 of 2298...\n",
      "Normalizing activity for neuron 53 of 2298...\n",
      "Normalizing activity for neuron 54 of 2298...\n",
      "Normalizing activity for neuron 55 of 2298...\n",
      "Normalizing activity for neuron 56 of 2298...\n",
      "Normalizing activity for neuron 57 of 2298...\n",
      "Normalizing activity for neuron 58 of 2298...\n",
      "Normalizing activity for neuron 59 of 2298...\n",
      "Normalizing activity for neuron 60 of 2298...\n",
      "Normalizing activity for neuron 61 of 2298...\n",
      "Normalizing activity for neuron 62 of 2298...\n",
      "Normalizing activity for neuron 63 of 2298...\n",
      "Normalizing activity for neuron 64 of 2298...\n",
      "Normalizing activity for neuron 65 of 2298...\n",
      "Normalizing activity for neuron 66 of 2298...\n",
      "Normalizing activity for neuron 67 of 2298...\n",
      "Normalizing activity for neuron 68 of 2298...\n",
      "Normalizing activity for neuron 69 of 2298...\n",
      "Normalizing activity for neuron 70 of 2298...\n",
      "Normalizing activity for neuron 71 of 2298...\n",
      "Normalizing activity for neuron 72 of 2298...\n",
      "Normalizing activity for neuron 73 of 2298...\n",
      "Normalizing activity for neuron 74 of 2298...\n",
      "Normalizing activity for neuron 75 of 2298...\n",
      "Normalizing activity for neuron 76 of 2298...\n",
      "Normalizing activity for neuron 77 of 2298...\n",
      "Normalizing activity for neuron 78 of 2298...\n",
      "Normalizing activity for neuron 79 of 2298...\n",
      "Normalizing activity for neuron 80 of 2298...\n",
      "Normalizing activity for neuron 81 of 2298...\n",
      "Normalizing activity for neuron 82 of 2298...\n",
      "Normalizing activity for neuron 83 of 2298...\n",
      "Normalizing activity for neuron 84 of 2298...\n",
      "Normalizing activity for neuron 85 of 2298...\n",
      "Normalizing activity for neuron 86 of 2298...\n",
      "Normalizing activity for neuron 87 of 2298...\n",
      "Normalizing activity for neuron 88 of 2298...\n",
      "Normalizing activity for neuron 89 of 2298...\n",
      "Normalizing activity for neuron 90 of 2298...\n",
      "Normalizing activity for neuron 91 of 2298...\n",
      "Normalizing activity for neuron 92 of 2298...\n",
      "Normalizing activity for neuron 93 of 2298...\n",
      "Normalizing activity for neuron 94 of 2298...\n",
      "Normalizing activity for neuron 95 of 2298...\n",
      "Normalizing activity for neuron 96 of 2298...\n",
      "Normalizing activity for neuron 97 of 2298...\n",
      "Normalizing activity for neuron 98 of 2298...\n",
      "Normalizing activity for neuron 99 of 2298...\n",
      "Normalizing activity for neuron 100 of 2298...\n",
      "Normalizing activity for neuron 101 of 2298...\n",
      "Normalizing activity for neuron 102 of 2298...\n",
      "Normalizing activity for neuron 103 of 2298...\n",
      "Normalizing activity for neuron 104 of 2298...\n",
      "Normalizing activity for neuron 105 of 2298...\n",
      "Normalizing activity for neuron 106 of 2298...\n",
      "Normalizing activity for neuron 107 of 2298...\n",
      "Normalizing activity for neuron 108 of 2298...\n",
      "Normalizing activity for neuron 109 of 2298...\n",
      "Normalizing activity for neuron 110 of 2298...\n",
      "Normalizing activity for neuron 111 of 2298...\n",
      "Normalizing activity for neuron 112 of 2298...\n",
      "Normalizing activity for neuron 113 of 2298...\n",
      "Normalizing activity for neuron 114 of 2298...\n",
      "Normalizing activity for neuron 115 of 2298...\n",
      "Normalizing activity for neuron 116 of 2298...\n",
      "Normalizing activity for neuron 117 of 2298...\n",
      "Normalizing activity for neuron 118 of 2298...\n",
      "Normalizing activity for neuron 119 of 2298...\n",
      "Normalizing activity for neuron 120 of 2298...\n",
      "Normalizing activity for neuron 121 of 2298...\n",
      "Normalizing activity for neuron 122 of 2298...\n",
      "Normalizing activity for neuron 123 of 2298...\n",
      "Normalizing activity for neuron 124 of 2298...\n",
      "Normalizing activity for neuron 125 of 2298...\n",
      "Normalizing activity for neuron 126 of 2298...\n",
      "Normalizing activity for neuron 127 of 2298...\n",
      "Normalizing activity for neuron 128 of 2298...\n",
      "Normalizing activity for neuron 129 of 2298...\n",
      "Normalizing activity for neuron 130 of 2298...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 129 is out of bounds for axis 0 with size 129",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m trial_indices \u001b[38;5;241m=\u001b[39m {sound: np\u001b[38;5;241m.\u001b[39marray([sdf[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m sound \u001b[38;5;28;01mfor\u001b[39;00m sdf \u001b[38;5;129;01min\u001b[39;00m neuron_sdfsound_out[neuron_i]]) \n\u001b[0;32m     21\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m sound \u001b[38;5;129;01min\u001b[39;00m sound_types}\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate baseline firing rate statistics\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m baseline_fr_mu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(\u001b[43mneuron_baseline\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneuron_i\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     25\u001b[0m baseline_fr_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanstd(neuron_baseline[neuron_i])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Stack and concatenate sound-aligned SDF\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 129 is out of bounds for axis 0 with size 129"
     ]
    }
   ],
   "source": [
    "# Assuming 'spike_log' is a DataFrame and other variables are already defined\n",
    "# Initialize dictionaries or lists to store results\n",
    "norm_fr_soundA = []\n",
    "norm_fr_soundC = []\n",
    "norm_fr_soundG = []\n",
    "norm_fr_soundF = []\n",
    "norm_fr_soundD = []\n",
    "norm_fr_sound_all = []\n",
    "norm_fr_sequence = []\n",
    "norm_fr_trialStart = []\n",
    "norm_fr_violation = []\n",
    "norm_fr_consistant = []\n",
    "\n",
    "# Normalize activity across sounds\n",
    "for neuron_i in range(len(spike_log)):\n",
    "    print(f'Normalizing activity for neuron {neuron_i + 1} of {len(spike_log)}...')\n",
    "\n",
    "    # Identify trials for each sound type (A, C, G, F, D)\n",
    "    sound_types = ['A', 'C', 'G', 'F', 'D']\n",
    "    trial_indices = {sound: np.array([sdf[2] == sound for sdf in neuron_sdfsound_out[neuron_i]]) \n",
    "                     for sound in sound_types}\n",
    "    \n",
    "    # Calculate baseline firing rate statistics\n",
    "    baseline_fr_mu = np.nanmean(neuron_baseline[neuron_i])\n",
    "    baseline_fr_std = np.nanstd(neuron_baseline[neuron_i])\n",
    "\n",
    "    print(baseline_fr_mu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Stack and concatenate sound-aligned SDF\n",
    "    sound_sdf_temp = np.vstack([sdf[0] for sdf in neuron_sdfsound_out[neuron_i]])\n",
    "    \n",
    "    # Calculate baseline firing rate for the sound-aligned SDF\n",
    "    baseline_window = slice(200 + (-100), 200 + 0)  # 100 ms before sound onset\n",
    "    sound_baseline_fr_mu = np.nanmean(np.nanmean(sound_sdf_temp[:, baseline_window], axis=1))\n",
    "    sound_baseline_fr_std = np.nanstd(np.nanmean(sound_sdf_temp[:, baseline_window], axis=1))\n",
    "    \n",
    "    # Normalize firing rates for each sound type\n",
    "    norm_fr = {}\n",
    "    for sound in sound_types:\n",
    "        trials = trial_indices[sound]\n",
    "        sound_sdf = np.vstack([sdf[0] for i, sdf in enumerate(neuron_sdfsound_out[neuron_i]) if trials[i]])\n",
    "        norm_fr[f'sound{sound}'] = (np.nanmean(sound_sdf, axis=0) - sound_baseline_fr_mu) / sound_baseline_fr_std\n",
    "    \n",
    "    # Normalize firing rates across all sound trials\n",
    "    all_sdf = np.vstack([sdf[0] for sdf in neuron_sdfsound_out[neuron_i]])\n",
    "    norm_fr_sound_all.append((np.nanmean(all_sdf, axis=0) - baseline_fr_mu) / baseline_fr_std)\n",
    "    \n",
    "    # Normalize firing rates for sequence and trial start\n",
    "    norm_fr_sequence.append((np.nanmean(neuron_sdfseq_out[neuron_i], axis=0) - baseline_fr_mu) / baseline_fr_std)\n",
    "    norm_fr_trialStart.append((np.nanmean(neuron_sdftrialstart_out[neuron_i], axis=0) - baseline_fr_mu) / baseline_fr_std)\n",
    "\n",
    "# Load event tables and normalize firing rates for violation and consistent trials\n",
    "for neuron_i in range(len(spike_log)):\n",
    "    datafile = spike_log.session.iloc[neuron_i]\n",
    "    # Load event table data\n",
    "    event_table = pd.read_csv(os.path.join(dirs[\"py_data\"], 'event_table', datafile + '-events.csv'))        \n",
    "\n",
    "    # Identify violation and consistent trials\n",
    "    viol_trials = event_table.index[event_table['cond_label'] == 'viol'].tolist()\n",
    "    cons_trials = event_table.index[event_table['cond_label'] == 'nonviol'].tolist()\n",
    "    \n",
    "    # Extract and store normalized firing rates for violation and consistent trials\n",
    "    norm_fr_violation.append(neuron_sdfviol_out[neuron_i][viol_trials, :])\n",
    "    norm_fr_consistant.append(neuron_sdfviol_out[neuron_i][cons_trials, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spiking activity\n",
    "# Determine neurons that have significant onset cue modulation\n",
    "\n",
    "\n",
    "# Determine neurons that have significant sequence modulation\n",
    "# Determine neurons that have significant reward modulation\n",
    "\n",
    "# Determine neurons that have significant violation modulation\n",
    "\n",
    "# Determine neurons that have theta modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laminar dynamics during auditory sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrolaminar profile of auditory and frontal cortex recordings \n",
    "# Current source density plots (sound onset; auditory cortex)\n",
    "# Current source density plots (reward delivery; frontal cortex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fronto-temporal interactions during auditory sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aglt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
